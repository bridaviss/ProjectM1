---
title: "Data Cleaning for RAKE and Phrases"
output: html_document
date: "2023-09-08"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(udpipe)
library(textrank)
```

Loading in data
```{r}
jobs <- read.csv("/Users/joshuataylor/Desktop/UVA /Fall 2023/DS 4002/linkedin data/job_postings.csv")

#jobs_copy <- read.csv("/Users/joshuataylor/Desktop/UVA /Fall 2023/DS 4002/linkedin data/job_postings.csv")
```

Data Cleaning: 
1. Filling empty strings with NAs so we can drop them later
```{r pressure, echo=FALSE}
jobs[ jobs == '' ] <- NA # Fill in empty strings with 

dim( jobs )# 15,886 rows and 27 columns 

summary( jobs ) #    For some reason, this function doesn't display the NAs of string variables
                     # So I had to manually calculate the NAs below to make sure it worked.
sum( is.na( jobs ) )

```

2. Deciding relevant parameters w/ explanation for dropped parameters 
```{r}
# Creating column index. Helps when choosing which columns to drop
jobs_col_index <- tibble( colnames( jobs ) ) 

# jobs_df <- jobs[ , -c( ) ]
# Columns I'm dropping
# 2 - company_id, we don't have a use to know which companies are which
# 3 - title, there are too many titles to collapse them into a few categories: length( unique( jobs$title ) )
# 5-7 - there's tons of missing data for our salary variables
# 8, pay_period - doesn't seem relevant, 9,000 NAs
# 9, formatted_work_type - this variable and work_type are the same 
# 10, location - too many different locations, over 3000
# 12, original_listed_time - nonsense
# 13, remote_allowed - +13,500 NAs, would be interesting to see how this correlated with applies 
# 14, views - could be useful later, but applies is a better indicator of job interest than views
# 15-19 & 21-24 - unrelated to our research question
# 26-27 - unrelated

table(jobs$work_type)
#length(table( jobs$remote_allowed ))

#table( jobs$compensation_type)

#sum(is.na(jobs$work_type))

#sum(is.na(jobs$formatted_work_type))

```

3. Correcting Variable Classes
```{r}
table( jobs$formatted_work_type )

jobs[ , c( 20, 25 ) ] <- lapply( jobs[ , c( 20, 25  ) ] , as.factor ) 
# We're converting formatted_work_experience and work_type to factor variables because they
# are categorial variables

#str(jobs)
```


4. Dropping columns and removing NAs
```{r}
# Dropping columns
jobs_df <- jobs[ , -c( 2, 3, 5:10, 12:19, 21:24, 26, 27 ) ]

# Removing NAs
jobs_df <- jobs_df[ complete.cases( jobs_df ) , ]

sum( is.na( jobs_df$formatted_experience_level ) ) # check to see if NAs were dropped
```

5. Subsetting the applies column into "low" & "high"
```{r}
summary( jobs_df$applies ) # the median number of applies will be out cutoff
                           # above the median number of applies will be categorised as "high"  
                           # and below will be "low"

jobs_df$applies_factor <- cut( jobs_df$applies , c( -1 , 6 , 1616 ) , labels = c( "low" , "high" ) )
# low: [ 0, 6 ] so a job with 6 applications is considered low 
# high: (6 , 1615 ] a job that received 7 or more applications is considered high 
```


6. Splitting Dataset into high and low
```{r}
df_high <- subset( jobs_df, applies_factor == 'high')

df_low <- subset( jobs_df, applies_factor == 'low')
```

Exploratory graphs
```{r}
applies_hist <- ggplot( jobs_df , aes( x = applies ) )+
  geom_histogram() + 
  labs(
    title = "Histogram of Job Applications" , 
    subtitle = "Most job applications are have less than 100 applications"
  )
applies_hist

exp_bar <- ggplot( jobs_df , aes( x = formatted_experience_level ) )+
  geom_bar() + 
  labs(
    title = "Bar Chart of Work Experience" , 
    subtitle = "Much of our data is from mid-senior level job postings"
  )
exp_bar


wrktyp_bar <- ggplot( jobs_df , aes( x = work_type ) )+
  geom_bar() + 
  labs(
    title = "Bar Chart of the Work Type" , 
    subtitle = "Most of the job postings are for full time jobs"
  )
wrktyp_bar
```





